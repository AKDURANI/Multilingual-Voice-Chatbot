{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fqrlNyq8OaYN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9de9ff01-d9a7-4669-e194-b4ddb5e804ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wavio in /usr/local/lib/python3.10/dist-packages (0.0.7)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from wavio) (1.23.5)\n",
            "Requirement already satisfied: sounddevice in /usr/local/lib/python3.10/dist-packages (0.4.6)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice) (2.21)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.22.0)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.0.2+cu118)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.32.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.10/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from flask-ngrok) (2.31.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (2.3.7)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask-ngrok) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->flask-ngrok) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.8->flask-ngrok) (2.1.3)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (6.0.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!pip install wavio\n",
        "!pip install sounddevice\n",
        "!pip install torch accelerate torchaudio datasets\n",
        "!pip install --upgrade transformers\n",
        "!pip install -q torchaudio omegaconf\n",
        "!pip install flask-ngrok\n",
        "!pip install pyngrok\n",
        "!ngrok config add-authtoken 2U1f33A1OBVeXaNZt9cSlJanE4f_7W4e2HoUeQ2iqrwZGpy2Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ILqCIC4_OlNr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86709df2-340e-45e5-8606-527ee8a7e51d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (20230314)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.56.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.1.0)\n",
            "Requirement already satisfied: tiktoken==0.3.1 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.3.1)\n",
            "Requirement already satisfied: ffmpeg-python==0.2.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python==0.2.0->openai-whisper) (0.18.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.1->openai-whisper) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.1->openai-whisper) (2.31.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.27.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (3.12.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper) (16.0.6)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U openai-whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Osk4-88dSgzj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6e29619-716e-4ff5-9361-14dfd69bca79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gtts in /usr/local/lib/python3.10/dist-packages (2.3.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gtts) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gtts) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gtts) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "!pip install gtts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "V67pcBFZiF1J"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUi2tzvyiXFC",
        "outputId": "8b0c697d-afdd-48eb-cd10-041cbe25060e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vavjyaEYihRG"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "\n",
        "def preprocess(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    stemmer = PorterStemmer()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove non-alphanumeric characters\n",
        "    tokens = nltk.word_tokenize(text.lower())\n",
        "    tokens = [token for token in tokens if token not in stopwords.words('english')]\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in lemmatized_tokens]\n",
        "    return ' '.join(stemmed_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HVPq5Ksrijch"
      },
      "outputs": [],
      "source": [
        "def preprocess_with_stopwords(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    stemmer = PorterStemmer()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove non-alphanumeric characters\n",
        "    tokens = nltk.word_tokenize(text.lower())\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    stemmed_tokens = [stemmer.stem(token) for token in lemmatized_tokens]\n",
        "    return ' '.join(stemmed_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "y9lml6lQ1PFG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import ISRIStemmer\n",
        "import re\n"
      ],
      "metadata": {
        "id": "hiQOEAKqmi4U"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OuRfdQNmnyQd"
      },
      "outputs": [],
      "source": [
        "#...............IMPORTING ASR MODEL.............\n",
        "import whisper\n",
        "model = whisper.load_model(\"tiny\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (Wav2Vec2Processor, Wav2Vec2ForCTC)\n",
        "import torchaudio\n",
        "import torch\n",
        "\n",
        "def speech_file_to_array_fn(voice_path, resampling_to=16000):\n",
        "    speech_array, sampling_rate = torchaudio.load(voice_path)\n",
        "    resampler = torchaudio.transforms.Resample(sampling_rate, resampling_to)\n",
        "\n",
        "    return resampler(speech_array)[0].numpy(), sampling_rate\n",
        "\n",
        "# load the model\n",
        "cp = \"bakrianoo/sinai-voice-ar-stt\"\n",
        "processor = Wav2Vec2Processor.from_pretrained(cp)\n",
        "modelA = Wav2Vec2ForCTC.from_pretrained(cp)"
      ],
      "metadata": {
        "id": "ZAM87t44wJCP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ApPRZBMcnyQe",
        "outputId": "c217672d-89f7-4f8e-a9d0-ca1b9cc6dffa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/usr/bin/python3'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import sys\n",
        "sys.executable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Dip17TQlPCYx"
      },
      "outputs": [],
      "source": [
        "#..............IMPORTING TTS MODEL..............\n",
        "\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvXD1Mg-nyQg",
        "outputId": "abf562c1-656d-402a-86b4-423d6ad2700f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import os\n",
        "import torch\n",
        "print(os.getcwd())\n",
        "def calculate_execution_time(func):\n",
        "    def wrapper(*args, **kwargs):\n",
        "        start_time = time.time()\n",
        "        result = func(*args, **kwargs)\n",
        "        end_time = time.time()\n",
        "        execution_time = end_time - start_time\n",
        "        print(f\"Function '{func.__name__}' execution time: {execution_time:.6f} seconds\")\n",
        "        return result\n",
        "    return wrapper\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "LgVgth00nyQg"
      },
      "outputs": [],
      "source": [
        "import scipy.io.wavfile as wav\n",
        "from scipy.io import wavfile\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1crg8tXSnyQg",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5561e4d4-93b7-484a-e0c3-990b0683591b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://01eb-34-91-4-67.ngrok-free.app\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [27/Aug/2023 20:46:23] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [27/Aug/2023 20:46:23] \"GET /staticFiles/bravo.css HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [27/Aug/2023 20:46:38] \"POST /success HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [27/Aug/2023 20:46:38] \"\u001b[36mGET /staticFiles/bravo.css HTTP/1.1\u001b[0m\" 304 -\n",
            "INFO:werkzeug:127.0.0.1 - - [27/Aug/2023 20:46:42] \"GET /charlie2 HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [27/Aug/2023 20:46:43] \"GET /staticFiles/style.css HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [27/Aug/2023 20:46:43] \"GET /staticFiles/index2.js HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [27/Aug/2023 20:46:43] \"GET /staticFiles/index2.css HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [27/Aug/2023 21:20:21] \"GET /charlie2 HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [27/Aug/2023 21:20:22] \"GET /staticFiles/index2.css HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [27/Aug/2023 21:20:22] \"GET /staticFiles/index2.js HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [27/Aug/2023 21:20:22] \"GET /staticFiles/style.css HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask, request, jsonify, render_template, send_file, flash, request, redirect, url_for\n",
        "import os\n",
        "import soundfile as sf\n",
        "import io\n",
        "import base64\n",
        "import scipy.signal as signal\n",
        "import torch\n",
        "import torchaudio\n",
        "\n",
        "app = Flask(__name__, template_folder='templateFiles', static_folder='staticFiles')\n",
        "run_with_ngrok(app)\n",
        "\n",
        "UPLOAD_FOLDER = \"/content/ALAM\"\n",
        "ALLOWED_EXTENSIONS = {'txt', 'pdf', 'png', 'jpg', 'jpeg', 'gif', \"csv\"}\n",
        "app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER\n",
        "\n",
        "# ML model logic\n",
        "def ml_model_prediction(audio_blob, questions_list, answers_list):\n",
        "\n",
        "    audio_blob.seek(0)\n",
        "\n",
        "\n",
        "    audio_data, _ = sf.read(io.BytesIO(audio_blob.read()))\n",
        "    sf.write(\"outputx.wav\", audio_data,48000 )\n",
        "\n",
        "    # Language Identification\n",
        "    audio = whisper.load_audio(\"outputx.wav\")\n",
        "    audio = whisper.pad_or_trim(audio)\n",
        "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "    _, probs = model.detect_language(mel)\n",
        "    language = max(probs, key=probs.get)\n",
        "    print(f\"Detected language:\", language)\n",
        "\n",
        "    if language == \"fr\" or language == \"en\" or language == \"de\":\n",
        "      result = model.transcribe(\"outputx.wav\")\n",
        "      transcription = result[\"text\"]\n",
        "      print(\"Transcription\", transcription)\n",
        "    else:\n",
        "      sample, sr = speech_file_to_array_fn(\"outputx.wav\")\n",
        "      inputs = processor([sample], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
        "\n",
        "      with torch.no_grad():\n",
        "          logits = modelA(inputs.input_values,).logits\n",
        "\n",
        "      predicted_ids = torch.argmax(logits, dim=-1)\n",
        "      text = processor.batch_decode(predicted_ids)\n",
        "      transcription = ' '.join(text)\n",
        "\n",
        "      print(\"Transcription:\",transcription)\n",
        "\n",
        "\n",
        "\n",
        "    #...................................................................\n",
        "\n",
        "    vectorizer = TfidfVectorizer(tokenizer=nltk.word_tokenize)\n",
        "    X = vectorizer.fit_transform([preprocess(q) for q in questions_list])\n",
        "\n",
        "    def get_response(text):\n",
        "      processed_text = preprocess_with_stopwords(text)\n",
        "      #print(\"processed_text:\", processed_text)\n",
        "      vectorized_text = vectorizer.transform([processed_text])\n",
        "      similarities = cosine_similarity(vectorized_text, X)\n",
        "      #print(\"similarities:\", similarities)\n",
        "      max_similarity = np.max(similarities)\n",
        "      #print(\"max_similarity:\", max_similarity)\n",
        "      if max_similarity > 0.6:\n",
        "          high_similarity_questions = [q for q, s in zip(questions_list, similarities[0]) if s > 0.6]\n",
        "          #print(\"high_similarity_questions:\", high_similarity_questions)\n",
        "\n",
        "          target_answers = []\n",
        "          for q in high_similarity_questions:\n",
        "              q_index = questions_list.index(q)\n",
        "              target_answers.append(answers_list[q_index])\n",
        "          #print(target_answers)\n",
        "\n",
        "          Z = vectorizer.fit_transform([preprocess_with_stopwords(q) for q in high_similarity_questions])\n",
        "          processed_text_with_stopwords = preprocess_with_stopwords(text)\n",
        "          #print(\"processed_text_with_stopwords:\", processed_text_with_stopwords)\n",
        "          vectorized_text_with_stopwords = vectorizer.transform([processed_text_with_stopwords])\n",
        "          final_similarities = cosine_similarity(vectorized_text_with_stopwords, Z)\n",
        "          closest = np.argmax(final_similarities)\n",
        "          return target_answers[closest]\n",
        "      else:\n",
        "          return \"I can't answer this question.\"\n",
        "\n",
        "\n",
        "    f_text = get_response(transcription)\n",
        "    print(\"BOT_ANSWER\", f_text)\n",
        "\n",
        "\n",
        "\n",
        "    #...................................................................\n",
        "\n",
        "    if language == \"fr\":\n",
        "      audio = gTTS(f_text , lang = \"fr\")\n",
        "    elif language == \"en\":\n",
        "      audio = gTTS(f_text , lang = \"en\")\n",
        "    elif language == \"de\":\n",
        "      audio = gTTS(f_text , lang = \"de\")\n",
        "    else:\n",
        "      audio = gTTS(f_text , lang = \"ar\")\n",
        "\n",
        "\n",
        "\n",
        "    #...................................................................\n",
        "\n",
        "    audio.save('output.wav') #save the string converted to speech as a .wav file\n",
        "    sound_file = 'output.wav'\n",
        "    Audio(sound_file, autoplay=True)\n",
        "    audio_path = '/content/output.wav'\n",
        "    return send_file(audio_path, mimetype='output/wav')\n",
        "\n",
        "\n",
        "# Serve the index.html file\n",
        "\n",
        "@app.route('/')\n",
        "@app.route('/main')\n",
        "def main():\n",
        "    return render_template('bravo.html')\n",
        "\n",
        "@app.route('/charlie1')\n",
        "def charlie1():\n",
        "    return render_template('lala -21.html')\n",
        "\n",
        "@app.route('/charlie2')\n",
        "def charlie2():\n",
        "    return render_template('lala -22.html')\n",
        "@app.route('/charlie3')\n",
        "def charlie3():\n",
        "    return render_template('lala -23.html')\n",
        "@app.route('/charlie4')\n",
        "def charlie4():\n",
        "    return render_template('lala -24.html')\n",
        "\n",
        "\n",
        "@app.route('/success', methods = ['POST'])\n",
        "def success():\n",
        "    if request.method == 'POST':\n",
        "        f = request.files['file']\n",
        "        f.save(f.filename)\n",
        "        return render_template('bravo.html')\n",
        "\n",
        "# @app.route('/index')\n",
        "# def index():\n",
        "#     return render_template('lala -2.html')\n",
        "\n",
        "# API endpoint for audio file upload and ML model prediction\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "\n",
        "    df = pd.read_csv(\"TEXT.csv\", encoding='utf-8')\n",
        "    questions_list = df['Questions'].tolist()\n",
        "    answers_list = df['Answers'].tolist()\n",
        "    print(\"Audio Recieved!\")\n",
        "\n",
        "    audio_blob = request.files['audio']\n",
        "\n",
        "    if not audio_blob:\n",
        "        return jsonify({'error': 'No audio file provided.'}), 400\n",
        "\n",
        "    # Perform prediction using ML model\n",
        "    predictions = ml_model_prediction(audio_blob, questions_list, answers_list)\n",
        "    return predictions\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}